{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "in Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]], columns=['cgpa', 'profile_score', 'lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:2]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "      \n",
    "  np.random.seed(3)\n",
    "  parameters = {}\n",
    "  L = len(layer_dims)         \n",
    "\n",
    "  for l in range(1, L):\n",
    "\n",
    "    parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n",
    "    parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "      \n",
    "\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "      \n",
    "  Z = np.dot(W.T, A_prev) + b\n",
    "  \n",
    "  return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Progation\n",
    "def L_layer_forward(X, parameters):\n",
    "    \n",
    "  A = X\n",
    "  L = len(parameters) // 2                  # number of layers in the neural network\n",
    "  \n",
    "  for l in range(1, L+1):\n",
    "    A_prev = A \n",
    "    Wl = parameters['W' + str(l)]\n",
    "    bl = parameters['b' + str(l)]\n",
    "    #print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "    #print(\"W\"+str(l)+\": \", Wl)\n",
    "    #print(\"b\"+str(l)+\": \", bl)\n",
    "    #print(\"--\"*20)\n",
    "\n",
    "    A = linear_forward(A_prev, Wl, bl)\n",
    "    #print(\"A\"+str(l)+\": \", A)\n",
    "    #print(\"**\"*20)\n",
    "          \n",
    "  return A,A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6],\n",
       "       [1.6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[3][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10658137, 0.10658137],\n",
       "        [0.10658137, 0.10658137]]),\n",
       " 'b1': array([[0.00082267],\n",
       "        [0.00082267]]),\n",
       " 'W2': array([[0.111776],\n",
       "        [0.111776]]),\n",
       " 'b2': array([[0.119136]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss -  25.321744156025517\n",
      "Epoch -  2 Loss -  18.320004165722047\n",
      "Epoch -  3 Loss -  9.473661050729628\n",
      "Epoch -  4 Loss -  3.2520938634031613\n",
      "Epoch -  5 Loss -  1.3407132589299962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.26507636, 0.38558861],\n",
       "        [0.27800387, 0.40980287]]),\n",
       " 'b1': array([[0.02749056],\n",
       "        [0.02974394]]),\n",
       " 'W2': array([[0.41165744],\n",
       "        [0.48302736]]),\n",
       " 'b2': array([[0.48646246]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append((y-y_hat)**2)\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from  tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(2,activation ='linear',input_dim =2))\n",
    "model.add(Dense(1,activation ='linear'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.8329072,  0.5477536],\n",
       "        [ 1.2123326,  1.0553113]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[ 0.7678491 ],\n",
       "        [-0.88008416]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights =[np.array([[0.1,0.1],[0.1,0.1]],dtype=np.float32),\n",
    "              np.array([0.,0.],dtype=np.float32),\n",
    "              np.array([[0.1],[0.1]],dtype=np.float32),\n",
    "              np.array([0.],dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "WARNING:tensorflow:From C:\\Users\\dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 35.0153\n",
      "Epoch 2/75\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 34.0890\n",
      "Epoch 3/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 33.1529\n",
      "Epoch 4/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 32.1530\n",
      "Epoch 5/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 31.2677\n",
      "Epoch 6/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 30.3094\n",
      "Epoch 7/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.4585\n",
      "Epoch 8/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 28.6275\n",
      "Epoch 9/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.7671\n",
      "Epoch 10/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 27.0022\n",
      "Epoch 11/75\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 26.2206\n",
      "Epoch 12/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 25.5249\n",
      "Epoch 13/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.8597\n",
      "Epoch 14/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.1555\n",
      "Epoch 15/75\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 23.4134\n",
      "Epoch 16/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.7326\n",
      "Epoch 17/75\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 22.1433\n",
      "Epoch 18/75\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.4962\n",
      "Epoch 19/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 21.0102\n",
      "Epoch 20/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 20.3526\n",
      "Epoch 21/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.7742\n",
      "Epoch 22/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 19.2528\n",
      "Epoch 23/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 18.7878\n",
      "Epoch 24/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.2943\n",
      "Epoch 25/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.8630\n",
      "Epoch 26/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.2779\n",
      "Epoch 27/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.8221\n",
      "Epoch 28/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.4492\n",
      "Epoch 29/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.1115\n",
      "Epoch 30/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 15.5760\n",
      "Epoch 31/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.2228\n",
      "Epoch 32/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 14.9428\n",
      "Epoch 33/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.5799\n",
      "Epoch 34/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.1293\n",
      "Epoch 35/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 13.8951\n",
      "Epoch 36/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.4884\n",
      "Epoch 37/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 13.2593\n",
      "Epoch 38/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.8854\n",
      "Epoch 39/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 12.6945\n",
      "Epoch 40/75\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.3993\n",
      "Epoch 41/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.0818\n",
      "Epoch 42/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 11.8697\n",
      "Epoch 43/75\n",
      "4/4 [==============================] - 0s 0s/step - loss: 11.7124\n",
      "Epoch 44/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 11.3684\n",
      "Epoch 45/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1611\n",
      "Epoch 46/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 10.9947\n",
      "Epoch 47/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 10.8553\n",
      "Epoch 48/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 10.6061\n",
      "Epoch 49/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 10.3827\n",
      "Epoch 50/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.1944\n",
      "Epoch 51/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 10.0567\n",
      "Epoch 52/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.9854\n",
      "Epoch 53/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.7766\n",
      "Epoch 54/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.6083\n",
      "Epoch 55/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 9.4782\n",
      "Epoch 56/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.3283\n",
      "Epoch 57/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 9.2004\n",
      "Epoch 58/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.0777\n",
      "Epoch 59/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.9168\n",
      "Epoch 60/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.8756\n",
      "Epoch 61/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.7004\n",
      "Epoch 62/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.6946\n",
      "Epoch 63/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.5129\n",
      "Epoch 64/75\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.4062\n",
      "Epoch 65/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.3474\n",
      "Epoch 66/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.2676\n",
      "Epoch 67/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 8.2000\n",
      "Epoch 68/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.1285\n",
      "Epoch 69/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.0494\n",
      "Epoch 70/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.9202\n",
      "Epoch 71/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.8488\n",
      "Epoch 72/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.7922\n",
      "Epoch 73/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.7618\n",
      "Epoch 74/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.6853\n",
      "Epoch 75/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.5745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c7724279d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,0:2].values,df.iloc[:,-1].values,epochs =75,verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
